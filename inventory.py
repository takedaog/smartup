import warnings
import pandas as pd
import requests
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from sqlalchemy import create_engine, text
from sqlalchemy.types import Float, Integer, String, DateTime, Boolean, NVARCHAR
import urllib
from sqlalchemy import inspect
pd.set_option('future.no_silent_downcasting', True)
warnings.filterwarnings(
    "ignore",
    message="Could not infer format",
    category=UserWarning
)

def get_cookies_from_browser(url: str) -> dict:
    chrome_options = Options()
    chrome_options.add_argument("--start-maximized")
    driver = webdriver.Chrome(options=chrome_options)
    driver.get(url)
    input("üåê –ê–≤—Ç–æ—Ä–∏–∑—É–π—Ç–µ—Å—å –≤ –±—Ä–∞—É–∑–µ—Ä–µ –∏ –Ω–∞–∂–º–∏—Ç–µ Enter...")
    cookies = {c['name']: c['value'] for c in driver.get_cookies()}
    driver.quit()
    return cookies

def auto_cast_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∞–≤—Ç–æ–∫–∞—Å—Ç–∏–Ω–≥:
    - –Ω–µ —É–¥–∞–ª—è–µ—Ç —Å—Ç—Ä–æ–∫–∏;
    - –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ü–µ–ª—ã–µ/–¥—Ä–æ–±–Ω—ã–µ/boolean;
    - –ø—ã—Ç–∞–µ—Ç—Å—è —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏ —Å –¥–∞—Ç–∞–º–∏ –ø–æ –¥–æ–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤ —Å—ç–º–ø–ª–µ.
    """
    if df is None or df.empty:
        return df
    df = df.copy()  # —è–≤–Ω–∞—è –∫–æ–ø–∏—è, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å SettingWithCopyWarning

    for col in df.columns:
        s_all = df[col].dropna().astype(str)
        if s_all.empty:
            continue
        try:
            # boolean true/false
            if s_all.str.lower().isin(['true', 'false']).all():
                df.loc[:, col] = s_all.str.lower().map({'true': 1, 'false': 0}).astype('Int64')
                continue

            # —Ü–µ–ª—ã–µ —á–∏—Å–ª–∞ (–≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫–æ–ª–æ–Ω–∫–∏ —Ü–µ–ª—ã–µ)
            if s_all.str.fullmatch(r"\d+").all():
                df.loc[:, col] = pd.to_numeric(s_all, downcast='integer', errors='coerce')
                continue

            # –¥—Ä–æ–±–Ω—ã–µ —á–∏—Å–ª–∞
            if s_all.str.fullmatch(r"\d+\.\d+").all():
                df.loc[:, col] = pd.to_numeric(s_all, errors='coerce')
                continue

            # –î–∞—Ça: –ø—Ä–æ–±—É–µ–º –ø–æ —Å—ç–º–ø–ª—É —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å, –µ—Å–ª–∏ >threshold –ø–∞—Ä—Å–∏—Ç—Å—è ‚Äî –ø—Ä–∏–≤–æ–¥–∏–º –≤—Å—é –∫–æ–ª–æ–Ω–∫—É
            sample = s_all.head(100)  # —Å–º–æ—Ç—Ä–∏–º –ø–µ—Ä–≤—ã–µ 100 –Ω–µ–ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
            parsed = pd.to_datetime(sample, errors='coerce', dayfirst=True)
            frac = parsed.notna().mean()  # –¥–æ–ª—è —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö –≤ —Å—ç–º–ø–ª–µ
            DATE_FRAC_THRESHOLD = 0.6
            if frac >= DATE_FRAC_THRESHOLD:
                # –ø—Ä–∏–≤–æ–¥–∏–º –≤—Å—é –∫–æ–ª–æ–Ω–∫—É –∫ datetime (errors='coerce' ‚Äî –Ω–µ —É–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏)
                df.loc[:, col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True)
                # –Ω–µ —É–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ –∑–¥–µ—Å—å!
                continue

            # –∏–Ω–∞—á–µ ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
        except Exception:
            # –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            continue

    return df


def fetch_inventory(data_url: str, cookies: dict) -> dict:
    print("‚¨áÔ∏è –ó–∞–≥—Ä—É–∑–∫–∞ inventory...")
    r = requests.post(
        data_url,
        cookies=cookies,
        json={},
        headers={"Content-Type": "application/json"}
    )
    r.raise_for_status()
    data = r.json()

    # debug: —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å/–ø–æ—Å—á–∏—Ç–∞—Ç—å —Å–∫–æ–ª—å–∫–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Ä–µ–∞–ª—å–Ω–æ –ø—Ä–∏—à–ª–æ
    items = data.get("inventory", [])
    print("üì° –í—Å–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ inventory (raw):", len(items))

    if not items:
        print("‚ö†Ô∏è –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
        return {}

    inv_df = pd.json_normalize(items, sep="_", max_level=1)
    print("üîé –ü–æ—Å–ª–µ json_normalize inv_df.shape:", inv_df.shape)
    # –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –ø–æ–∫–∞–∑–∞—Ç—å –ø–µ—Ä–≤—ã–µ 5 –∫–æ–ª–æ–Ω–æ–∫ –∏ –ø–µ—Ä–≤—ã—Ö 3 —Å—Ç—Ä–æ–∫:
    print("columns sample:", inv_df.columns[:10].tolist())
    print(inv_df.head(3).to_dict(orient='records'))

    groups_list, kinds_list, sectors_list = [], [], []
    for it in items:
        pid = it.get("product_id")
        for g in it.get("groups", []):
            g["product_id"] = pid
            groups_list.append(g)
        for k in it.get("inventory_kinds", []):
            k["product_id"] = pid
            kinds_list.append(k)
        for s in it.get("sector_codes", []):
            s["product_id"] = pid
            sectors_list.append(s)

    return {
        "inventory_main":   inv_df,
        "inventory_groups": pd.DataFrame(groups_list),
        "inventory_kinds":  pd.DataFrame(kinds_list),
        "inventory_sectors":pd.DataFrame(sectors_list)
    }

UNIQUE_KEYS = {
    "inventory_main":   ["product_id"],
    "inventory_groups": ["product_id", "group_id"],
    "inventory_kinds":  ["product_id", "kind_id"],
    "inventory_sectors":["product_id", "sector_code"],
}

def upload_to_sql(df_dict: dict):
    params = urllib.parse.quote_plus(
        "DRIVER={ODBC Driver 17 for SQL Server};"
        "SERVER=localhost;"
        "DATABASE=Epco;"
        "Trusted_Connection=yes;"
        "TrustServerCertificate=yes;"
    )
    engine = create_engine(f"mssql+pyodbc:///?odbc_connect={params}")
    inspector = inspect(engine)

    with engine.begin() as conn:
        for table_name, df in df_dict.items():
            if df is None or df.empty:
                print(f"‚è≠ {table_name} –ø—É—Å—Ç ‚Äì –ø—Ä–æ–ø—É—â–µ–Ω–æ.")
                continue

            df = auto_cast_dataframe(df)
            keys = [k for k in UNIQUE_KEYS.get(table_name, []) if k in df.columns]
            if keys:
                df[keys] = df[keys].fillna('').astype(str).apply(lambda x: x.str.strip())
                df = df.drop_duplicates(subset=keys)

            # –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ NVARCHAR –¥–ª—è –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–ª–µ–π
            dtype_map = {}
            for col in df.columns:
                val = df[col].dropna().iloc[0] if not df[col].dropna().empty else None
                if val is None: dtype_map[col] = NVARCHAR()   # ‚Üê —é–Ω–∏–∫–æ–¥
                elif isinstance(val, float): dtype_map[col] = Float()
                elif isinstance(val, int): dtype_map[col] = Integer()
                elif isinstance(val, bool): dtype_map[col] = Boolean()
                elif hasattr(val, "year"): dtype_map[col] = DateTime()
                else: dtype_map[col] = NVARCHAR()             # ‚Üê —é–Ω–∏–∫–æ–¥

            if not inspector.has_table(table_name):
                df.to_sql(table_name, con=conn, index=False,
                          if_exists="replace", dtype=dtype_map)
                print(f"üÜï {table_name} —Å–æ–∑–¥–∞–Ω–∞ –∏ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫.")
                continue

            if keys:
                stg = f"{table_name}_stg"
                df.to_sql(stg, con=conn, index=False, if_exists="replace", dtype=dtype_map)
                on_clause = " AND ".join([f"t.[{k}] = s.[{k}]" for k in keys])
                cols = [f"[{c}]" for c in df.columns]
                insert_cols = ", ".join(cols)
                insert_vals = ", ".join([f"s.[{c}]" for c in df.columns])
                merge_sql = f"""
MERGE INTO dbo.{table_name} AS t
USING dbo.{stg} AS s
ON {on_clause}
WHEN NOT MATCHED BY TARGET THEN
    INSERT ({insert_cols}) VALUES ({insert_vals});
DROP TABLE dbo.{stg};
"""
                conn.execute(text(merge_sql))
                print(f"üì• {table_name} ‚Üí –¥–æ–±–∞–≤–ª–µ–Ω—ã —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ ({len(df)} –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ).")
            else:
                df.to_sql(table_name, con=conn, index=False,
                          if_exists="append", dtype=dtype_map)
                print(f"‚ö†Ô∏è {table_name}: –Ω–µ—Ç –∫–ª—é—á–µ–π, –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤—Å–µ {len(df)} —Å—Ç—Ä–æ–∫.")

if __name__ == "__main__":
    DATA_URL = "https://smartup.online/b/anor/mxsx/mr/inventory$export"
    cookies = get_cookies_from_browser("https://smartup.online")
    result = fetch_inventory(DATA_URL, cookies)
    if result:
        upload_to_sql(result)
